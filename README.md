# Workshop on Building Big Data Pipeline with Apache Spark

Apache Spark is an open source big data processing framework built around speed, ease of use, and sophisticated analytics

#What is Big Data?
 - Large Volume of Data
    - Structured
    - UnStructured
       - Volume
       - Verity
       - Velocity

# Big Data Pipeline
<img src = "https://github.com/Jayaradha/WorkShop/blob/master/Screen%20Shot%202016-09-13%20at%2011.04.15%20AM.png?raw=true">

# Lecture

By the end of this lecture, you will be able to:

- Create RDDs to distribute data across a cluster

- Use the Spark shell to compose and execute Spark commands

- Use Spark to analyze apache access.log file

# Practice Lab 

 - Analyse Stock price using Spark
